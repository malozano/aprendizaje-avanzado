<!DOCTYPE html><html lang="es" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Apuntes de la asignatura Aprendizaje Avanzado del Grado en Ingenier√≠a en Inteligencia Artificial de la Universidad de Alicante">
      
      
        <meta name="author" content="Miguel Angel Lozano">
      
      
        <link rel="canonical" href="https://malozano.github.io/aprendizaje-avanzado/05-adaboost/">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.1.1">
    
    
      
        <title>AdaBoost - Aprendizaje Avanzado</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.402914a4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.a0c5b2b5.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <link href="../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#adaboost" class="md-skip">
          Saltar a contenido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabecera">
    <a href=".." title="Aprendizaje Avanzado" class="md-header__button md-logo" aria-label="Aprendizaje Avanzado" data-md-component="logo">
      
  <img src="../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Aprendizaje Avanzado
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              AdaBoost
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo" aria-label="Modo oscuro" type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Modo oscuro" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
            </label>
          
        
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="white" data-md-color-accent="blue" aria-label="Modo claro" type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Modo claro" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="B√∫squeda" placeholder="B√∫squeda" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Buscar">
        
        <button type="reset" class="md-search__icon md-icon" title="Limpiar" aria-label="Limpiar" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando b√∫squeda
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navegaci√≥n" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Aprendizaje Avanzado" class="md-nav__button md-logo" aria-label="Aprendizaje Avanzado" data-md-component="logo">
      
  <img src="../images/logo.png" alt="logo">

    </a>
    Aprendizaje Avanzado
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Introducci√≥n
      </a>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2">
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          Bloque I. Aprendizaje supervisado
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Bloque I. Aprendizaje supervisado
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../01-modelos-no-param/" class="md-nav__link">
        1. Modelos param√©tricos y no param√©tricos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02-svm/" class="md-nav__link">
        2. SVM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03-arboles-decision/" class="md-nav__link">
        3. √Årboles de decisi√≥n
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3">
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          Pr√°cticas
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Pr√°cticas
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../practicas/00-datos-y-visualizacion/" class="md-nav__link">
        0. Datos y visualizaci√≥n
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="adaboost">AdaBoost<a class="headerlink" href="#adaboost" title="Permanent link">¬∂</a></h1>
<h2 id="4-boosting">4. Boosting<a class="headerlink" href="#4-boosting" title="Permanent link">¬∂</a></h2>
<p>Boosting entrena modelos secuencialmente, donde cada nuevo modelo se enfoca en corregir los errores cometidos por el ensemble actual.</p>
<p><strong>Diferencias clave con los m√©todos anteriores:</strong>
- Voting/Stacking/Bagging: Modelos <strong>independientes</strong> (paralelos)
- Boosting: Modelos <strong>dependientes</strong> (secuenciales)</p>
<p><strong>Caracter√≠sticas principales:</strong>
- Reduce principalmente el <strong>sesgo</strong> (y tambi√©n algo la varianza)
- Los modelos se entrenan <strong>secuencialmente</strong>
- Cada modelo se enfoca en los ejemplos mal clasificados o en los residuos
- Los modelos se combinan mediante suma ponderada
- Usa t√≠picamente <strong>clasificadores d√©biles</strong></p>
<h3 id="clasificadores-debiles-vs-clasificadores-fuertes">Clasificadores D√©biles vs Clasificadores Fuertes<a class="headerlink" href="#clasificadores-debiles-vs-clasificadores-fuertes" title="Permanent link">¬∂</a></h3>
<p><strong>Contexto: Un concepto espec√≠fico de Boosting</strong></p>
<p>El marco te√≥rico de clasificadores d√©biles y fuertes es <strong>espec√≠fico del paradigma de boosting</strong>. No se aplica de la misma manera a bagging, voting o stacking. Este concepto surge de la teor√≠a de aprendizaje computacional (computational learning theory) y es fundamental para entender c√≥mo y por qu√© funciona boosting.</p>
<h4 id="definiciones">Definiciones<a class="headerlink" href="#definiciones" title="Permanent link">¬∂</a></h4>
<p><strong>Clasificador d√©bil (weak learner):</strong>
Un clasificador que es solo ligeramente mejor que el azar. Formalmente, para clasificaci√≥n binaria, un clasificador d√©bil es aquel cuya tasa de error es:</p>
<div class="arithmatex">\[\epsilon &lt; \frac{1}{2}\]</div>
<p>Es decir, su accuracy debe ser mayor que 50% (mejor que lanzar una moneda). No necesita ser muy preciso, solo consistentemente mejor que adivinar al azar.</p>
<p><strong>Clasificador fuerte (strong learner):</strong>
Un clasificador con alta precisi√≥n, capaz de aproximarse arbitrariamente bien a la funci√≥n objetivo. Su tasa de error puede ser tan peque√±a como se desee con suficientes datos y capacidad del modelo.</p>
<h4 id="ejemplos-practicos">Ejemplos Pr√°cticos<a class="headerlink" href="#ejemplos-practicos" title="Permanent link">¬∂</a></h4>
<p><strong>Clasificadores d√©biles t√≠picos:</strong>
- <strong>Decision stumps</strong>: √Årboles de decisi√≥n con una √∫nica divisi√≥n (profundidad = 1)
</p><div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>  if x‚ÇÅ &gt; 5:
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>      return +1
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>  else:
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>      return -1
</code></pre></div>
- <strong>√Årboles poco profundos</strong>: √Årboles con profundidad m√°xima 2-3
- <strong>Reglas simples</strong>: "Si feature &gt; threshold ‚Üí clase positiva"
- <strong>Clasificadores lineales</strong> en problemas no lineales<p></p>
<p><strong>Clasificadores fuertes:</strong>
- Redes neuronales profundas
- √Årboles de decisi√≥n muy profundos
- SVMs con kernels complejos
- Random Forests
- Gradient Boosting Machines</p>
<h4 id="el-teorema-fundamental-del-boosting">El Teorema Fundamental del Boosting<a class="headerlink" href="#el-teorema-fundamental-del-boosting" title="Permanent link">¬∂</a></h4>
<p>Uno de los resultados m√°s importantes en teor√≠a de aprendizaje autom√°tico es que <strong>un conjunto de clasificadores d√©biles puede combinarse para formar un clasificador fuerte</strong>.</p>
<p><strong>Teorema (Schapire, 1990):</strong>
Si existe un clasificador d√©bil que puede lograr error menor que 1/2 - Œ≥ (donde Œ≥ &gt; 0), entonces existe un algoritmo de boosting que puede combinarlo para lograr un error arbitrariamente peque√±o en el conjunto de entrenamiento.</p>
<p>Este teorema es revolucionario porque:
1. Demuestra que la "debilidad" es suficiente para el aprendizaje
2. Proporciona una garant√≠a matem√°tica sobre boosting
3. Es constructivo: muestra c√≥mo construir el clasificador fuerte</p>
<h4 id="por-que-usar-clasificadores-debiles">¬øPor qu√© usar clasificadores d√©biles?<a class="headerlink" href="#por-que-usar-clasificadores-debiles" title="Permanent link">¬∂</a></h4>
<p>Aunque pueda parecer contraintuitivo usar modelos "d√©biles", hay razones importantes:</p>
<ol>
<li><strong>Prevenci√≥n de overfitting:</strong> </li>
<li>Modelos d√©biles tienen baja varianza</li>
<li>Menos propensos a memorizar ruido</li>
<li>
<p>La combinaci√≥n reduce overfitting</p>
</li>
<li>
<p><strong>Eficiencia computacional:</strong></p>
</li>
<li>Decision stumps son extremadamente r√°pidos</li>
<li>
<p>Podemos entrenar cientos o miles r√°pidamente</p>
</li>
<li>
<p><strong>Interpretabilidad:</strong></p>
</li>
<li>Cada modelo d√©bil es simple de entender</li>
<li>
<p>La combinaci√≥n mantiene cierta trazabilidad</p>
</li>
<li>
<p><strong>Teor√≠a s√≥lida:</strong></p>
</li>
<li>Garant√≠as matem√°ticas de convergencia</li>
<li>Bounds en el error de generalizaci√≥n</li>
</ol>
<h4 id="visualizacion-conceptual">Visualizaci√≥n Conceptual<a class="headerlink" href="#visualizacion-conceptual" title="Permanent link">¬∂</a></h4>
<p>Imaginemos un problema de clasificaci√≥n binaria en 2D:
</p><div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>Clasificador d√©bil 1 (divisi√≥n vertical):  
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>    |  +  -  |
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>    |  +  -  |
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>    |  -  +  |
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>Clasificador d√©bil 2 (divisi√≥n horizontal):
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>    --------
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>    +  +  +
<a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>    -  -  -
<a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>    --------
<a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>
<a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>Clasificador d√©bil 3 (divisi√≥n diagonal):
<a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>      /  +  +
<a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>     /  +  -
<a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>    /  -  -
<a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>
<a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>Combinaci√≥n (clasificador fuerte):
<a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>    Regiones complejas y precisas
<a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>    mediante la suma ponderada
</code></pre></div><p></p>
<p>Cada clasificador d√©bil captura un patr√≥n simple, pero su combinaci√≥n puede representar fronteras de decisi√≥n arbitrariamente complejas.</p>
<h4 id="analogia-con-la-vida-real">Analog√≠a con la Vida Real<a class="headerlink" href="#analogia-con-la-vida-real" title="Permanent link">¬∂</a></h4>
<p>Piensa en un panel de expertos versus un comit√© de conocedores:</p>
<p><strong>Clasificador fuerte = Experto individual:</strong>
- Una persona altamente capacitada
- Puede cometer errores por sesgos personales
- Costoso de formar/entrenar
- Si se equivoca, el error es grande</p>
<p><strong>Clasificadores d√©biles = Comit√© de personas:</strong>
- Cada persona sabe algo √∫til pero limitado
- Combinados, sus opiniones diversas capturan m√°s informaci√≥n
- M√°s econ√≥mico formar muchas personas con conocimiento b√°sico
- Los errores individuales se compensan</p>
<h4 id="requerimientos-para-clasificadores-debiles">Requerimientos para Clasificadores D√©biles<a class="headerlink" href="#requerimientos-para-clasificadores-debiles" title="Permanent link">¬∂</a></h4>
<p>Para que un clasificador d√©bil sea √∫til en un ensemble debe cumplir:</p>
<ol>
<li><strong>Mejor que el azar:</strong> <span class="arithmatex">\(P(\text{correcto}) &gt; 0.5\)</span></li>
<li><strong>Diversidad:</strong> Cometer errores diferentes a otros clasificadores</li>
<li><strong>Eficiencia:</strong> Ser r√°pido de entrenar</li>
<li><strong>Estabilidad m√≠nima:</strong> No ser extremadamente sensible a peque√±os cambios</li>
</ol>
<h4 id="clasificadores-debiles-en-la-practica">Clasificadores D√©biles en la Pr√°ctica<a class="headerlink" href="#clasificadores-debiles-en-la-practica" title="Permanent link">¬∂</a></h4>
<p><strong>AdaBoost t√≠picamente usa:</strong>
- Decision stumps (√°rboles de profundidad 1)
- Accuracy individual: 55-70%
- Combinaci√≥n de 50-500 stumps ‚Üí accuracy &gt; 95%</p>
<p><strong>Gradient Boosting t√≠picamente usa:</strong>
- √Årboles de profundidad 3-8
- Cada √°rbol captura interacciones de bajo orden
- Combinaci√≥n de 100-1000 √°rboles</p>
<h4 id="ejemplo-numerico">Ejemplo Num√©rico<a class="headerlink" href="#ejemplo-numerico" title="Permanent link">¬∂</a></h4>
<p>Consideremos un problema donde queremos clasificar si un correo es spam:
</p><div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="c1"># Clasificador d√©bil 1: "Si contiene 'gratis' ‚Üí spam"</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="n">accuracy_1</span> <span class="o">=</span> <span class="mf">0.60</span>  <span class="c1"># 60% correcto</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="c1"># Clasificador d√©bil 2: "Si tiene &gt;3 signos $ ‚Üí spam"  </span>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">accuracy_2</span> <span class="o">=</span> <span class="mf">0.58</span>  <span class="c1"># 58% correcto</span>
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="c1"># Clasificador d√©bil 3: "Si todas may√∫sculas ‚Üí spam"</span>
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a><span class="n">accuracy_3</span> <span class="o">=</span> <span class="mf">0.55</span>  <span class="c1"># 55% correcto</span>
<a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>
<a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a><span class="c1"># Individualmente son d√©biles, pero...</span>
<a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a><span class="c1"># Combinados con AdaBoost:</span>
<a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a><span class="n">ensemble_accuracy</span> <span class="o">=</span> <span class="mf">0.94</span>  <span class="c1"># 94% correcto!</span>
</code></pre></div><p></p>
<p>Cada regla individual es imperfecta, pero la combinaci√≥n inteligente de muchas reglas simples crea un clasificador robusto.</p>
<h4 id="conexion-con-sesgo-varianza">Conexi√≥n con Sesgo-Varianza<a class="headerlink" href="#conexion-con-sesgo-varianza" title="Permanent link">¬∂</a></h4>
<p>Los clasificadores d√©biles y fuertes se relacionan con el trade-off sesgo-varianza:</p>
<p><strong>Clasificadores d√©biles:</strong>
- Alto sesgo (no pueden capturar patrones complejos)
- Baja varianza (estables ante cambios en datos)
- Ejemplo: decision stump siempre divide igual</p>
<p><strong>Clasificadores fuertes:</strong>
- Bajo sesgo (pueden aprender patrones complejos)
- Alta varianza (sensibles a datos de entrenamiento)
- Ejemplo: √°rbol profundo memoriza detalles</p>
<p><strong>Ensemble de clasificadores d√©biles (Boosting):</strong>
- Reduce sesgo mediante combinaci√≥n aditiva secuencial
- Mantiene baja varianza de modelos individuales
- <strong>Mejor de ambos mundos</strong></p>
<hr>
<h2 id="41-adaboost-adaptive-boosting">4.1. AdaBoost (Adaptive Boosting)<a class="headerlink" href="#41-adaboost-adaptive-boosting" title="Permanent link">¬∂</a></h2>
<p>AdaBoost es el primer algoritmo de boosting exitoso y responde directamente a la pregunta: <strong>¬øPodemos convertir clasificadores d√©biles en un clasificador fuerte?</strong></p>
<p>Desarrollado por Freund y Schapire (1997), AdaBoost gan√≥ el premio G√∂del Prize por su importancia te√≥rica y pr√°ctica.</p>
<h3 id="idea-central">Idea Central<a class="headerlink" href="#idea-central" title="Permanent link">¬∂</a></h3>
<p>AdaBoost funciona de forma adaptativa:
1. Entrena un clasificador d√©bil
2. <strong>Aumenta el peso</strong> de los ejemplos mal clasificados
3. Entrena el siguiente clasificador en datos <strong>ponderados</strong>
4. Repite el proceso
5. Combina todos los clasificadores con pesos seg√∫n su accuracy</p>
<p><strong>Met√°fora:</strong> Es como un estudiante que identifica sus errores en un examen y se concentra m√°s en estudiar esos temas para el siguiente examen.</p>
<h3 id="algoritmo-detallado">Algoritmo Detallado<a class="headerlink" href="#algoritmo-detallado" title="Permanent link">¬∂</a></h3>
<p><strong>Inicializaci√≥n:</strong>
</p><div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>Dataset: D = {(x‚ÇÅ,y‚ÇÅ), ..., (x‚Çô,y‚Çô)} donde y·µ¢ ‚àà {-1, +1}
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>Inicializar pesos uniformes: w‚ÇÅ(i) = 1/n para i = 1, ..., n
</code></pre></div><p></p>
<p><strong>Para t = 1 hasta T:</strong></p>
<p><strong>Paso 1: Entrenar clasificador d√©bil</strong>
</p><div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>Entrenar clasificador h‚Çú en D con distribuci√≥n de pesos w‚Çú
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>(Los ejemplos con mayor peso tienen m√°s influencia)
</code></pre></div><p></p>
<p><strong>Paso 2: Calcular error ponderado</strong>
</p><div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>Œµ‚Çú = Œ£·µ¢ w‚Çú(i) ¬∑ ùüô(h‚Çú(x·µ¢) ‚â† y·µ¢)
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>Donde ùüô es la funci√≥n indicadora (1 si error, 0 si correcto)
</code></pre></div><p></p>
<p><strong>Paso 3: Calcular peso del clasificador</strong>
</p><div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>Œ±‚Çú = (1/2) ¬∑ ln((1 - Œµ‚Çú) / Œµ‚Çú)
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>Interpretaci√≥n:
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>- Si Œµ‚Çú peque√±o (buen clasificador) ‚Üí Œ±‚Çú grande (mucho peso)
<a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>- Si Œµ‚Çú = 0.5 (azar) ‚Üí Œ±‚Çú = 0 (sin peso)
<a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>- Si Œµ‚Çú &gt; 0.5 (peor que azar) ‚Üí Œ±‚Çú negativo (invertir predicci√≥n)
</code></pre></div><p></p>
<p><strong>Paso 4: Actualizar pesos de ejemplos</strong>
</p><div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>w‚Çú‚Çä‚ÇÅ(i) = w‚Çú(i) ¬∑ exp(-Œ±‚Çú ¬∑ y·µ¢ ¬∑ h‚Çú(x·µ¢))
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>Simplificado:
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>- Si h‚Çú clasifica correctamente x·µ¢: w‚Çú‚Çä‚ÇÅ(i) disminuye
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>- Si h‚Çú clasifica incorrectamente x·µ¢: w‚Çú‚Çä‚ÇÅ(i) aumenta
</code></pre></div><p></p>
<p><strong>Paso 5: Normalizar pesos</strong>
</p><div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>w‚Çú‚Çä‚ÇÅ(i) = w‚Çú‚Çä‚ÇÅ(i) / Œ£‚±º w‚Çú‚Çä‚ÇÅ(j)
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>(Para que los pesos sumen 1)
</code></pre></div><p></p>
<p><strong>Predicci√≥n final:</strong>
</p><div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>H(x) = sign(Œ£‚Çú‚Çå‚ÇÅ·µÄ Œ±‚Çú ¬∑ h‚Çú(x))
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>Es decir, suma ponderada de todos los clasificadores
</code></pre></div><p></p>
<h3 id="ejemplo-paso-a-paso">Ejemplo Paso a Paso<a class="headerlink" href="#ejemplo-paso-a-paso" title="Permanent link">¬∂</a></h3>
<p>Consideremos un ejemplo simple con 10 puntos:
</p><div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="c1"># Dataset</span>
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">,</span> <span class="n">x4</span><span class="p">,</span> <span class="n">x5</span><span class="p">,</span> <span class="n">x6</span><span class="p">,</span> <span class="n">x7</span><span class="p">,</span> <span class="n">x8</span><span class="p">,</span> <span class="n">x9</span><span class="p">,</span> <span class="n">x10</span><span class="p">]</span>
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a><span class="c1"># Iteraci√≥n 1:</span>
<a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a><span class="c1"># Pesos iniciales: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]</span>
<a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a><span class="c1"># Clasificador d√©bil h‚ÇÅ: clasifica bien el 70% (Œµ‚ÇÅ = 0.3)</span>
<a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a><span class="c1"># Œ±‚ÇÅ = 0.5 * ln((1-0.3)/0.3) = 0.42</span>
<a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a><span class="c1"># </span>
<a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a><span class="c1"># Errores en: x4, x7, x9</span>
<a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a><span class="c1"># Nuevos pesos (normalizados):</span>
<a id="__codelineno-10-12" name="__codelineno-10-12" href="#__codelineno-10-12"></a><span class="c1"># Correctos: peso disminuye a ~0.07</span>
<a id="__codelineno-10-13" name="__codelineno-10-13" href="#__codelineno-10-13"></a><span class="c1"># Incorrectos: peso aumenta a ~0.17</span>
<a id="__codelineno-10-14" name="__codelineno-10-14" href="#__codelineno-10-14"></a>
<a id="__codelineno-10-15" name="__codelineno-10-15" href="#__codelineno-10-15"></a><span class="c1"># Iteraci√≥n 2:</span>
<a id="__codelineno-10-16" name="__codelineno-10-16" href="#__codelineno-10-16"></a><span class="c1"># Ahora h‚ÇÇ se entrena dando m√°s importancia a x4, x7, x9</span>
<a id="__codelineno-10-17" name="__codelineno-10-17" href="#__codelineno-10-17"></a><span class="c1"># h‚ÇÇ clasifica bien el 80% en datos ponderados</span>
<a id="__codelineno-10-18" name="__codelineno-10-18" href="#__codelineno-10-18"></a><span class="c1"># Œ±‚ÇÇ = 0.5 * ln((1-0.2)/0.2) = 0.69</span>
<a id="__codelineno-10-19" name="__codelineno-10-19" href="#__codelineno-10-19"></a><span class="c1"># ...</span>
<a id="__codelineno-10-20" name="__codelineno-10-20" href="#__codelineno-10-20"></a>
<a id="__codelineno-10-21" name="__codelineno-10-21" href="#__codelineno-10-21"></a><span class="c1"># Predicci√≥n final:</span>
<a id="__codelineno-10-22" name="__codelineno-10-22" href="#__codelineno-10-22"></a><span class="c1"># H(x) = sign(0.42*h‚ÇÅ(x) + 0.69*h‚ÇÇ(x) + 0.54*h‚ÇÉ(x) + ...)</span>
</code></pre></div><p></p>
<h3 id="propiedades-importantes">Propiedades Importantes<a class="headerlink" href="#propiedades-importantes" title="Permanent link">¬∂</a></h3>
<h4 id="training-error-bound">Training Error Bound<a class="headerlink" href="#training-error-bound" title="Permanent link">¬∂</a></h4>
<p>AdaBoost tiene una garant√≠a te√≥rica sobre el error de entrenamiento:</p>
<div class="arithmatex">\[\text{Training Error} \leq \prod_{t=1}^{T} \sqrt{\epsilon_t(1-\epsilon_t)} \leq \exp\left(-2\sum_{t=1}^{T}\gamma_t^2\right)\]</div>
<p>Donde <span class="arithmatex">\(\gamma_t = 0.5 - \epsilon_t\)</span> es el "margen" del clasificador d√©bil.</p>
<p><strong>Implicaci√≥n:</strong> Si cada clasificador d√©bil es solo ligeramente mejor que el azar (<span class="arithmatex">\(\epsilon_t &lt; 0.5\)</span>), el error de entrenamiento converge exponencialmente r√°pido a 0.</p>
<h4 id="no-requiere-conocer-t-de-antemano">No requiere conocer Œµ‚Çú de antemano<a class="headerlink" href="#no-requiere-conocer-t-de-antemano" title="Permanent link">¬∂</a></h4>
<p>A diferencia de otros m√©todos, AdaBoost:
- No necesita que especifiques qu√© tan "d√©bil" es tu clasificador
- Se adapta autom√°ticamente seg√∫n el error observado
- Funciona con cualquier clasificador d√©bil v√°lido</p>
<h3 id="implementacion-en-scikit-learn">Implementaci√≥n en scikit-learn<a class="headerlink" href="#implementacion-en-scikit-learn" title="Permanent link">¬∂</a></h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="c1"># AdaBoost con decision stumps (default)</span>
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a><span class="n">ada</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>    <span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># Decision stump</span>
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>         <span class="c1"># N√∫mero de clasificadores d√©biles</span>
<a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>       <span class="c1"># Peso en la actualizaci√≥n (default=1.0)</span>
<a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>    <span class="n">algorithm</span><span class="o">=</span><span class="s1">'SAMME.R'</span><span class="p">,</span>     <span class="c1"># SAMME.R usa probabilidades (mejor)</span>
<a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a><span class="p">)</span>
<a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a>
<a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a><span class="n">ada</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<a id="__codelineno-11-14" name="__codelineno-11-14" href="#__codelineno-11-14"></a>
<a id="__codelineno-11-15" name="__codelineno-11-15" href="#__codelineno-11-15"></a><span class="c1"># Inspeccionar clasificadores y pesos</span>
<a id="__codelineno-11-16" name="__codelineno-11-16" href="#__codelineno-11-16"></a><span class="nb">print</span><span class="p">(</span><span class="s2">"Pesos de clasificadores:"</span><span class="p">,</span> <span class="n">ada</span><span class="o">.</span><span class="n">estimator_weights_</span><span class="p">)</span>
<a id="__codelineno-11-17" name="__codelineno-11-17" href="#__codelineno-11-17"></a><span class="nb">print</span><span class="p">(</span><span class="s2">"Errores de clasificadores:"</span><span class="p">,</span> <span class="n">ada</span><span class="o">.</span><span class="n">estimator_errors_</span><span class="p">)</span>
</code></pre></div>
<h3 id="variantes-de-adaboost">Variantes de AdaBoost<a class="headerlink" href="#variantes-de-adaboost" title="Permanent link">¬∂</a></h3>
<h4 id="samme-stagewise-additive-modeling-using-a-multiclass-exponential-loss">SAMME (Stagewise Additive Modeling using a Multiclass Exponential loss)<a class="headerlink" href="#samme-stagewise-additive-modeling-using-a-multiclass-exponential-loss" title="Permanent link">¬∂</a></h4>
<p>Generalizaci√≥n de AdaBoost para m√°s de 2 clases:</p>
<div class="arithmatex">\[\alpha_t = \ln\left(\frac{1-\epsilon_t}{\epsilon_t}\right) + \ln(K-1)\]</div>
<p>Donde K es el n√∫mero de clases.</p>
<h4 id="sammer-real-valued-predictions">SAMME.R (Real-valued predictions)<a class="headerlink" href="#sammer-real-valued-predictions" title="Permanent link">¬∂</a></h4>
<p>Usa probabilidades en lugar de predicciones discretas:
- M√°s suave y generalmente mejor rendimiento
- Requiere que el clasificador base tenga <code>predict_proba</code>
- Es el default en scikit-learn</p>
<h3 id="ventajas-de-adaboost">Ventajas de AdaBoost<a class="headerlink" href="#ventajas-de-adaboost" title="Permanent link">¬∂</a></h3>
<ul>
<li><strong>Simple conceptualmente:</strong> F√°cil de entender e implementar</li>
<li><strong>Garant√≠as te√≥ricas fuertes:</strong> Bounds en error de entrenamiento</li>
<li><strong>Flexible:</strong> Funciona con cualquier clasificador d√©bil</li>
<li><strong>Poco tuning:</strong> Pocos hiperpar√°metros</li>
<li><strong>No requiere conocer Œµ:</strong> Se adapta autom√°ticamente</li>
<li><strong>Efectivo:</strong> Puede alcanzar alta accuracy con clasificadores muy simples</li>
</ul>
<h3 id="limitaciones-de-adaboost">Limitaciones de AdaBoost<a class="headerlink" href="#limitaciones-de-adaboost" title="Permanent link">¬∂</a></h3>
<ul>
<li><strong>Sensible a ruido y outliers:</strong> Les da mucho peso</li>
<li><strong>Sensible a overfitting:</strong> Con muchas iteraciones</li>
<li><strong>No paralelizable:</strong> Los clasificadores deben entrenarse secuencialmente</li>
<li><strong>Puede ser lento:</strong> Con clasificadores d√©biles lentos</li>
<li><strong>Requiere clasificadores d√©biles apropiados:</strong> No funciona con clasificadores peores que el azar</li>
</ul>
<h3 id="cuando-usar-adaboost">Cu√°ndo usar AdaBoost<a class="headerlink" href="#cuando-usar-adaboost" title="Permanent link">¬∂</a></h3>
<p><strong>Usar AdaBoost cuando:</strong>
- ‚úÖ Tienes un <strong>clasificador d√©bil</strong> bueno y r√°pido
- ‚úÖ Dataset <strong>limpio</strong> (poco ruido)
- ‚úÖ Quieres entender <strong>boosting conceptualmente</strong>
- ‚úÖ Clasificaci√≥n binaria o multiclase simple
- ‚úÖ Dataset peque√±o-mediano</p>
<p><strong>Considerar alternativas cuando:</strong>
- ‚ùå Dataset con mucho <strong>ruido/outliers</strong> ‚Üí Gradient Boosting m√°s robusto
- ‚ùå Buscas <strong>m√°ximo rendimiento</strong> ‚Üí XGBoost/LightGBM
- ‚ùå Dataset muy grande ‚Üí LightGBM m√°s eficiente
- ‚ùå Muchas features categ√≥ricas ‚Üí CatBoost</p>
<h3 id="ejemplo-completo">Ejemplo Completo<a class="headerlink" href="#ejemplo-completo" title="Permanent link">¬∂</a></h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">learning_curve</span>
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>
<a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a><span class="c1"># Generar datos</span>
<a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
<a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>                          <span class="n">n_redundant</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a>
<a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a><span class="c1"># Decision stump individual</span>
<a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a><span class="n">stump</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a><span class="n">stump</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Decision stump: </span><span class="si">{</span><span class="n">stump</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a>
<a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a><span class="c1"># AdaBoost con stumps</span>
<a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a><span class="n">ada</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
<a id="__codelineno-12-20" name="__codelineno-12-20" href="#__codelineno-12-20"></a>    <span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<a id="__codelineno-12-21" name="__codelineno-12-21" href="#__codelineno-12-21"></a>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-12-22" name="__codelineno-12-22" href="#__codelineno-12-22"></a>    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-12-23" name="__codelineno-12-23" href="#__codelineno-12-23"></a>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<a id="__codelineno-12-24" name="__codelineno-12-24" href="#__codelineno-12-24"></a><span class="p">)</span>
<a id="__codelineno-12-25" name="__codelineno-12-25" href="#__codelineno-12-25"></a><span class="n">ada</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<a id="__codelineno-12-26" name="__codelineno-12-26" href="#__codelineno-12-26"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"AdaBoost (100 stumps): </span><span class="si">{</span><span class="n">ada</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-12-27" name="__codelineno-12-27" href="#__codelineno-12-27"></a>
<a id="__codelineno-12-28" name="__codelineno-12-28" href="#__codelineno-12-28"></a><span class="c1"># Analizar evoluci√≥n del error</span>
<a id="__codelineno-12-29" name="__codelineno-12-29" href="#__codelineno-12-29"></a><span class="n">train_errors</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-12-30" name="__codelineno-12-30" href="#__codelineno-12-30"></a><span class="n">test_errors</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-12-31" name="__codelineno-12-31" href="#__codelineno-12-31"></a><span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">101</span><span class="p">):</span>
<a id="__codelineno-12-32" name="__codelineno-12-32" href="#__codelineno-12-32"></a>    <span class="n">ada_temp</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
<a id="__codelineno-12-33" name="__codelineno-12-33" href="#__codelineno-12-33"></a>        <span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<a id="__codelineno-12-34" name="__codelineno-12-34" href="#__codelineno-12-34"></a>        <span class="n">n_estimators</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
<a id="__codelineno-12-35" name="__codelineno-12-35" href="#__codelineno-12-35"></a>        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<a id="__codelineno-12-36" name="__codelineno-12-36" href="#__codelineno-12-36"></a>    <span class="p">)</span>
<a id="__codelineno-12-37" name="__codelineno-12-37" href="#__codelineno-12-37"></a>    <span class="n">ada_temp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<a id="__codelineno-12-38" name="__codelineno-12-38" href="#__codelineno-12-38"></a>    <span class="n">train_errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ada_temp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<a id="__codelineno-12-39" name="__codelineno-12-39" href="#__codelineno-12-39"></a>    <span class="n">test_errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ada_temp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<a id="__codelineno-12-40" name="__codelineno-12-40" href="#__codelineno-12-40"></a>
<a id="__codelineno-12-41" name="__codelineno-12-41" href="#__codelineno-12-41"></a><span class="c1"># Visualizar</span>
<a id="__codelineno-12-42" name="__codelineno-12-42" href="#__codelineno-12-42"></a><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<a id="__codelineno-12-43" name="__codelineno-12-43" href="#__codelineno-12-43"></a><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">101</span><span class="p">),</span> <span class="n">train_errors</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Train Error'</span><span class="p">)</span>
<a id="__codelineno-12-44" name="__codelineno-12-44" href="#__codelineno-12-44"></a><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">101</span><span class="p">),</span> <span class="n">test_errors</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Test Error'</span><span class="p">)</span>
<a id="__codelineno-12-45" name="__codelineno-12-45" href="#__codelineno-12-45"></a><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'N√∫mero de clasificadores'</span><span class="p">)</span>
<a id="__codelineno-12-46" name="__codelineno-12-46" href="#__codelineno-12-46"></a><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Error'</span><span class="p">)</span>
<a id="__codelineno-12-47" name="__codelineno-12-47" href="#__codelineno-12-47"></a><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<a id="__codelineno-12-48" name="__codelineno-12-48" href="#__codelineno-12-48"></a><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Evoluci√≥n del error en AdaBoost'</span><span class="p">)</span>
<a id="__codelineno-12-49" name="__codelineno-12-49" href="#__codelineno-12-49"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<h3 id="comparacion-adaboost-vs-bagging">Comparaci√≥n: AdaBoost vs Bagging<a class="headerlink" href="#comparacion-adaboost-vs-bagging" title="Permanent link">¬∂</a></h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span><span class="p">,</span> <span class="n">AdaBoostClassifier</span>
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a><span class="c1"># Bagging de stumps</span>
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a><span class="n">bagging_stumps</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>    <span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a><span class="p">)</span>
<a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a>
<a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a><span class="c1"># AdaBoost de stumps</span>
<a id="__codelineno-13-11" name="__codelineno-13-11" href="#__codelineno-13-11"></a><span class="n">adaboost_stumps</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
<a id="__codelineno-13-12" name="__codelineno-13-12" href="#__codelineno-13-12"></a>    <span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<a id="__codelineno-13-13" name="__codelineno-13-13" href="#__codelineno-13-13"></a>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-13-14" name="__codelineno-13-14" href="#__codelineno-13-14"></a>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<a id="__codelineno-13-15" name="__codelineno-13-15" href="#__codelineno-13-15"></a><span class="p">)</span>
<a id="__codelineno-13-16" name="__codelineno-13-16" href="#__codelineno-13-16"></a>
<a id="__codelineno-13-17" name="__codelineno-13-17" href="#__codelineno-13-17"></a><span class="n">bagging_stumps</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<a id="__codelineno-13-18" name="__codelineno-13-18" href="#__codelineno-13-18"></a><span class="n">adaboost_stumps</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<a id="__codelineno-13-19" name="__codelineno-13-19" href="#__codelineno-13-19"></a>
<a id="__codelineno-13-20" name="__codelineno-13-20" href="#__codelineno-13-20"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Bagging: </span><span class="si">{</span><span class="n">bagging_stumps</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-13-21" name="__codelineno-13-21" href="#__codelineno-13-21"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"AdaBoost: </span><span class="si">{</span><span class="n">adaboost_stumps</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</code></pre></div>
<p><strong>Resultado t√≠pico:</strong>
</p><div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>Bagging: 0.78
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>AdaBoost: 0.92
</code></pre></div><p></p>
<p>AdaBoost supera a Bagging con clasificadores d√©biles porque:
- Bagging reduce varianza (pero stumps ya tienen baja varianza)
- AdaBoost reduce sesgo (stumps tienen alto sesgo)</p>
<hr>





                
              </article>
            </div>
          
          
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg>
            Volver al principio
          </a>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.sections", "navigation.expand", "navigation.top", "navigation.indexes", "toc.follow", "toc.integrate", "search.suggest", "search.highlight", "content.code.copy", "content.code.annotate"], "search": "../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copiado al portapapeles", "clipboard.copy": "Copiar al portapapeles", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.term.missing": "Falta", "select.version": "Seleccionar versi\u00f3n"}}</script>
    
    
      <script src="../assets/javascripts/bundle.b78d2936.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>