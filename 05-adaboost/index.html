<!DOCTYPE html><html lang="es" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Apuntes de la asignatura Aprendizaje Avanzado del Grado en Ingeniería en Inteligencia Artificial de la Universidad de Alicante">
      
      
        <meta name="author" content="Miguel Angel Lozano">
      
      
        <link rel="canonical" href="https://malozano.github.io/aprendizaje-avanzado/05-adaboost/">
      
      
        <link rel="prev" href="../04-random-forest/">
      
      
        <link rel="next" href="../06-gradient-boosting/">
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.1.1">
    
    
      
        <title>5. Boosting. Adaboost - Aprendizaje Avanzado</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.402914a4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.a0c5b2b5.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <link href="../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#boosting" class="md-skip">
          Saltar a contenido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabecera">
    <a href=".." title="Aprendizaje Avanzado" class="md-header__button md-logo" aria-label="Aprendizaje Avanzado" data-md-component="logo">
      
  <img src="../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Aprendizaje Avanzado
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              5. Boosting. Adaboost
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo" aria-label="Modo oscuro" type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Modo oscuro" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
            </label>
          
        
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="white" data-md-color-accent="blue" aria-label="Modo claro" type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Modo claro" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Búsqueda" placeholder="Búsqueda" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Buscar">
        
        <button type="reset" class="md-search__icon md-icon" title="Limpiar" aria-label="Limpiar" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando búsqueda
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navegación" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Aprendizaje Avanzado" class="md-nav__button md-logo" aria-label="Aprendizaje Avanzado" data-md-component="logo">
      
  <img src="../images/logo.png" alt="logo">

    </a>
    Aprendizaje Avanzado
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Introducción
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          Bloque I. Aprendizaje supervisado
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Bloque I. Aprendizaje supervisado
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../01-modelos-no-param/" class="md-nav__link">
        1. Modelos paramétricos y no paramétricos. Logistic Regression
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02-svm/" class="md-nav__link">
        2. SVM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03-arboles-decision/" class="md-nav__link">
        3. Árboles de decisión
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04-random-forest/" class="md-nav__link">
        4. Métodos de ensemble. Random Forest
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          5. Boosting. Adaboost
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        5. Boosting. Adaboost
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#combinacion-de-clasificadores" class="md-nav__link">
    Combinación de clasificadores
  </a>
  
    <nav class="md-nav" aria-label="Combinación de clasificadores">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#clasificadores-debiles" class="md-nav__link">
    Clasificadores débiles
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clasificadores-fuertes" class="md-nav__link">
    Clasificadores fuertes
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#base-fundacional" class="md-nav__link">
    Base fundacional
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#muestreo-y-votos-ponderados" class="md-nav__link">
    Muestreo y votos ponderados
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adaboost-adaptive-boosting" class="md-nav__link">
    AdaBoost (Adaptive Boosting)
  </a>
  
    <nav class="md-nav" aria-label="AdaBoost (Adaptive Boosting)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#actualizacion-de-los-pesos" class="md-nav__link">
    Actualización de los pesos
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#entrenar-un-clasificador-debil" class="md-nav__link">
    Entrenar un clasificador débil
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calcular-el-peso-del-clasificador" class="md-nav__link">
    Calcular el peso del clasificador
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algoritmo-detallado" class="md-nav__link">
    Algoritmo detallado
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#propiedades-de-adaboost" class="md-nav__link">
    Propiedades de AdaBoost
  </a>
  
    <nav class="md-nav" aria-label="Propiedades de AdaBoost">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adaptatividad" class="md-nav__link">
    Adaptatividad
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cota-del-error-de-entrenamiento" class="md-nav__link">
    Cota del error de entrenamiento
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variantes-de-adaboost" class="md-nav__link">
    Variantes de AdaBoost
  </a>
  
    <nav class="md-nav" aria-label="Variantes de AdaBoost">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#clasificacion-multiclase-con-samme" class="md-nav__link">
    Clasificación multiclase con SAMME
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaboostr2-para-regresion" class="md-nav__link">
    AdaBoost.R2 para regresión
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementacion" class="md-nav__link">
    Implementación
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#consideraciones-finales" class="md-nav__link">
    Consideraciones finales
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06-gradient-boosting/" class="md-nav__link">
        6. Gradient Boosting
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3">
      
      
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          Prácticas
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Prácticas
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../practicas/00-datos-y-visualizacion/" class="md-nav__link">
        0. Datos y visualización
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../practicas/01-aprendizaje-supervisado/" class="md-nav__link">
        1. Aprendizaje supervisado
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="boosting">Boosting<a class="headerlink" href="#boosting" title="Permanent link">¶</a></h1>
<p><em>Boosting</em> es un meta-algoritmo de aprendizaje automático, que busca <strong>reducir principalmente el sesgo</strong>, aunque también algo la varianza. </p>
<p>A diferencia de los métodos de <em>ensemble</em> estudiados hasta el momento (<em>Voting</em>, <em>Stacking</em>, <em>Bagging</em>), en los que contábamos con modelos independientes que se entrenaban en paralelo, <em>Boosting</em> entrena los modelos secuencialmente, de forma que cada nuevo modelo se centra en corregir los errores cometidos por el <em>ensemble</em> actual.</p>
<h2 id="combinacion-de-clasificadores">Combinación de clasificadores<a class="headerlink" href="#combinacion-de-clasificadores" title="Permanent link">¶</a></h2>
<p>La idea que buscamos con <em>Boosting</em> es combinar una serie de <strong>clasificadores débiles</strong> para construir un <strong>clasificador fuerte</strong>. Los definimos de la siguiente forma:</p>
<ul>
<li>
<p><strong>Clasificador débil (weak learner):</strong> Se trata de clasificadores simples que funcionan mejor que la clasificación aleatoria. Es decir, su <em>accuracy</em> debe ser mayor que 50% (mejor que lanzar una moneda). Formalmente, para clasificación binaria, un clasificador débil debe cumplir que su tasa de error sea
<span class="arithmatex">\(\epsilon &lt; \frac{1}{2}\)</span>.</p>
</li>
<li>
<p><strong>Clasificador fuerte (strong learner):</strong> Se trata de un clasificador con alta precisión, capaz de aproximarse arbitrariamente bien a la función objetivo. Su tasa de error puede ser tan pequeña como se desee con suficientes datos y suficiente capacidad del modelo.</p>
</li>
</ul>
<h3 id="clasificadores-debiles">Clasificadores débiles<a class="headerlink" href="#clasificadores-debiles" title="Permanent link">¶</a></h3>
<p>Algunos de los ejemplos de clasificadores débiles típicos son los siguientes:</p>
<ul>
<li>
<p><strong>Decision stumps</strong>: Árboles de decisión con una única división (profundidad <span class="arithmatex">\(1\)</span>). Equivale a una regla simple, como por ejemplo, "si <span class="arithmatex">\(x_1 &gt; 5\)</span> entonces clase positiva, si no, clase negativa".</p>
</li>
<li>
<p><strong>Árboles poco profundos</strong>: Árboles con profundidad máxima <span class="arithmatex">\(2\)</span> o <span class="arithmatex">\(3\)</span>.</p>
</li>
<li>
<p><strong>Clasificadores lineales</strong> en problemas no lineales.</p>
</li>
</ul>
<h3 id="clasificadores-fuertes">Clasificadores fuertes<a class="headerlink" href="#clasificadores-fuertes" title="Permanent link">¶</a></h3>
<p>A continuación mostramos algunos ejemplos de clasificadores fuertes típicos:</p>
<ul>
<li>Redes neuronales profundas</li>
<li>Árboles de decisión muy profundos</li>
<li>SVMs con <em>kernels</em> complejos</li>
<li>Random Forests</li>
<li>Gradient Boosting</li>
</ul>
<h2 id="base-fundacional">Base fundacional<a class="headerlink" href="#base-fundacional" title="Permanent link">¶</a></h2>
<p>En 1988 y 1989 Kearns y Valiant (Kearns &amp; Valiant, 1988, 1989)<sup id="fnref:kearns1988cryptographic"><a class="footnote-ref" href="#fn:kearns1988cryptographic">1</a></sup> <sup id="fnref:kearns1989cryptographic"><a class="footnote-ref" href="#fn:kearns1989cryptographic">2</a></sup> plantearon la pregunta que constituye la fundación teórica del <em>Boosting</em>: <strong>"¿Puede un conjunto de clasificadores débiles crear un único clasificador fuerte?"</strong>. </p>
<p>En 1990 Schapire (Schapire, 1990)<sup id="fnref:schapire1990strength"><a class="footnote-ref" href="#fn:schapire1990strength">3</a></sup> demuestra que esto es posible, lo cual supone uno de los resultados más importantes en teoría de aprendizaje automático. Lo que nos dice el teorema que plantea es que si existe un clasificador débil que puede lograr error menor que <span class="arithmatex">\(1/2 - \gamma\)</span> (donde <span class="arithmatex">\(\gamma &gt; 0\)</span>), entonces existe un algoritmo de <em>Boosting</em> que puede combinarlo para lograr un error arbitrariamente pequeño en el conjunto de entrenamiento.</p>
<p>Este teorema es importante porque:</p>
<ol>
<li>Demuestra que la "debilidad" es suficiente para el aprendizaje.</li>
<li>Proporciona una garantía matemática sobre los métodos de <em>Boosting</em>.</li>
<li>Nos muestra cómo construir el clasificador fuerte.</li>
</ol>
<p>En este punto, nos podemos plantear la pregunta "¿Por qué usar clasificadores débiles?". Aunque pueda parecer contraintuitivo usar modelos "débiles", hay varios motivos para hacerlo:</p>
<ol>
<li>
<p><strong>Prevención del <em>overfitting</em>:</strong>  Los modelos débiles tienen baja varianza, son menos propensos a aprender el ruido, y la combinación de modelos reduce el <em>overfitting</em>.</p>
</li>
<li>
<p><strong>Eficiencia computacional:</strong> Modelos sencillos como los <em>decision stumps</em> son extremadamente rápidos. Podemos entrenar cientos o miles de ellos de forma eficiente.</p>
</li>
<li>
<p><strong>Interpretabilidad:</strong> Cada modelo débil es fácil de entender, y la combinación de modelos mantiene cierta trazabilidad.</p>
</li>
<li>
<p><strong>Teoría sólida:</strong> Existen garantías matemáticas de convergencia y el error de generalización puede ser acotado.</p>
</li>
</ol>
<p>Para que un clasificador débil sea útil en un <em>ensemble</em> debe cumplir:</p>
<ol>
<li><strong>Mejor que el azar:</strong> Su error debe ser <span class="arithmatex">\(\epsilon &lt; 0.5\)</span>.</li>
<li><strong>Diversidad:</strong> Debe cometer errores diferentes a los que cometen otros clasificadores.</li>
<li><strong>Eficiencia:</strong> Debe ser rápido de entrenar.</li>
<li><strong>Estabilidad:</strong> No debe ser extremadamente sensible a pequeños cambios en los datos.</li>
</ol>
<p>Respecto a la relación con el problema <strong>sesgo-varianza</strong>, los clasificadores débiles tendrán un alto sesgo, pero baja varianza (deben ser estables ante cambios en los datos). Por el contrario, los clasificadores fuertes tendrán bajo sesgo, ya que pueden aprender patrones complejos, pero una alta varianza, ya que serán más sensibles a los datos de entrenamiento.</p>
<p>Un <em>ensemble</em> de clasificadores débiles reducirá el sesgo, al combinar de forma secuencial los clasificadores, manteniendo la baja varianza de los modelos individuales, obteniendo así lo mejor de cada tipo de clasificador. </p>
<h2 id="muestreo-y-votos-ponderados">Muestreo y votos ponderados<a class="headerlink" href="#muestreo-y-votos-ponderados" title="Permanent link">¶</a></h2>
<p>Como hemos comentado, una de las principales diferencias de <em>Boosting</em> con los métodos de <em>ensemble</em> vistos anteriormente es que en lugar de entrenar los modelos en paralelo, <em>Boosting</em> realiza el entrenamiento secuencialmente, buscando que los nuevos clasificadores débiles corrijan los principales errores del <em>ensemble</em> actual. Para ello introduce ponderación a dos niveles: <strong>en el muestreo de ejemplos de entrenamiento</strong> y en <strong>la importancia de cada clasificador</strong>.</p>
<p>Si recordamos las características de los métodos de <em>Bagging</em>, tenemos:</p>
<ul>
<li><em>Bagging</em> realiza un muestreo aleatorio de los ejemplos de entrada para entrenar cada clasificador, pero todos estos ejemplos de entrada reciben el mismo peso.</li>
<li><em>Bagging</em> da la misma importancia a todos los clasificadores. El voto de cada clasificador vale lo mismo.</li>
</ul>
<p>A diferencia de esto, <em>Boosting</em> introduce:</p>
<ul>
<li>
<p><strong>Muestreo ponderado</strong>: No se da el mismo peso a todos los ejemplos de entrenamiento. El entrenamiento se concentrará en los ejemplos más difíciles. Intuitivamente, podríamos considerar que aquellos ejemplos cercanos a la frontera de decisión son más difíciles de clasificar, y deberían por lo tanto recibir pesos más altos. Podemos establecer una relación entre esto y los vectores de soporte en SVM, ya que en ambos casos buscamos basarnos en los ejemplos más difíciles de clasificar para obtener el clasificador. </p>
</li>
<li>
<p><strong>Votos ponderados</strong>: Se da diferente peso a los diferentes clasificadores, que al combinarlos se obtiene un "voto ponderado". Esto, junto a la estrategia de muestreo anterior, ayudará a producir un clasificador más fuerte.</p>
</li>
</ul>
<p>Considerando que contamos con un <em>dataset</em> <span class="arithmatex">\(\mathcal{D}\)</span> con <span class="arithmatex">\(N\)</span> ejemplos de entrenamiento <span class="arithmatex">\((\mathbf{x}_i, y_i)\)</span>, con <span class="arithmatex">\(i = 1, 2, \ldots, N\)</span>, y <span class="arithmatex">\(T\)</span> clasificadores débiles <span class="arithmatex">\(h_1, h_2, \ldots, h_T\)</span>, definimos:</p>
<ul>
<li>
<p><span class="arithmatex">\(w_i^{(t)}\)</span>: Peso del ejemplo de entrenamiento <span class="arithmatex">\((\mathbf{x}_i, y_i)\)</span> para entrenar el clasificador <span class="arithmatex">\(h_t\)</span>.</p>
</li>
<li>
<p><span class="arithmatex">\(\alpha_t\)</span>: Peso del clasificador <span class="arithmatex">\(h_t\)</span> en la votación del <em>ensemble</em>.</p>
</li>
</ul>
<p>De esta forma, para el caso de clasificación binaria con <span class="arithmatex">\(y_i \in \{-1, 1\}\)</span>, podemos definir el <em>ensemble</em> como:</p>
<div class="arithmatex">\[
F(\mathbf{x}) = \sum_{t=1}^T \alpha_t h_t(\mathbf{x})
\]</div>
<p>Es decir, la predicción de cada clasificador <span class="arithmatex">\(h_t\)</span> estará ponderada por el peso <span class="arithmatex">\(\alpha_t\)</span>, pudiendo así dar mayor peso a los clasificadores con menor error. La predicción final vendría dada por el signo de la función anterior:</p>
<div class="arithmatex">\[
H(\mathbf{x}) = \text{signo} \left( F(\mathbf{x}) \right)
\]</div>
<h2 id="adaboost-adaptive-boosting">AdaBoost (<em>Adaptive Boosting</em>)<a class="headerlink" href="#adaboost-adaptive-boosting" title="Permanent link">¶</a></h2>
<p>AdaBoost (Freund &amp; Schapire, 1997)<sup id="fnref:freund1997decision"><a class="footnote-ref" href="#fn:freund1997decision">4</a></sup> fue desarrollado por Freund y Schapire en 1997, y constituye el primer algoritmo de <em>Boosting</em> exitoso.</p>
<p>La idea central de este algoritmo es:</p>
<ol>
<li>Entrenar un <strong>clasificador débil</strong>.</li>
<li><strong>Aumentar el peso</strong> de los ejemplos mal clasificados.</li>
<li>Entrenar el siguiente clasificador con los <strong>datos ponderados</strong>.</li>
<li><strong>Repetir</strong> el proceso.</li>
<li><strong>Combinar</strong> todos los clasificadores ajustando sus pesos según su <em>accuracy</em>.</li>
</ol>
<p>Considerando el caso de clasificación binaria, donde <span class="arithmatex">\(y_i \in \{ -1, 1\}\)</span>, el <strong>algoritmo AdaBoost</strong> buscará minimizar la <strong>pérdida exponencial</strong>, que se define como:</p>
<div class="arithmatex">\[
L(y, F) = \sum_{i=1}^N e^{-y_i F(\mathbf{x}_i)} 
\]</div>
<p>Podemos observar que esta función de pérdida penaliza aquellos ejemplos en los que <span class="arithmatex">\(y_i\)</span> y <span class="arithmatex">\(F(\mathbf{x}_i)\)</span> tengan distinto signo, es decir, aquellos que están mal clasificados. Además, la pérdida no crece linealmente con el error, sino de forma exponencial. Un ejemplo muy mal clasificado contribuirá a la pérdida de forma desproporcionada.</p>
<p>A nivel general, el algoritmo AdaBoost realizará los siguientes pasos:</p>
<div class="arithmatex">\[
\begin{align*}
&amp; \text{Entrada: } \text{Conjunto de entrenamiento } \mathcal{D}= \{(\mathbf{x}_i, y_i)\}_{i=1}^N \text{ con } y_i \in \{-1, +1\} \\
&amp; w_i^{(1)} \leftarrow \frac{1}{N} \quad \forall i \in 1, 2, \ldots, N \quad \text{(Inicializa todos los ejemplos con peso uniforme)} \\
&amp; \text{Para  } t = 1, \ldots, T \\
&amp; \quad h_t \leftarrow \text{Entrenar un clasificador débil con los pesos } \mathbf{w}^{(t)} \\
&amp; \quad \alpha_t \leftarrow \text{Calcular el peso del clasificador } h_t \\
&amp; \quad w_i^{(t+1)} \leftarrow \text{Actualiza los pesos de los ejemplos para el siguiente clasificador } \forall i \\
&amp; \text{Devuelve: } H(\mathbf{x}) = \text{signo} \left( F(\mathbf{x}) \right) = \text{signo} \left( \sum_{t=1}^T \alpha_t h_t(\mathbf{x}) \right)
\end{align*}
\]</div>
<p>El algoritmo construye el <em>ensemble</em> de forma voraz, iteración a iteración. En cada iteración <span class="arithmatex">\(t\)</span> añade al <em>ensemble</em> un nuevo clasificador <span class="arithmatex">\(h_t\)</span>. Para entrenarlo presta especial atención a los ejemplos de entrenamiento que tengan un mayor peso <span class="arithmatex">\(w_i^{(t)}\)</span> en dicha iteración.</p>
<p>Vamos a continuación a detallar cada uno de los pasos de este algoritmo.</p>
<blockquote>
<p><strong>Nota</strong>: La derivación que presentamos aquí, basada en la minimización de la pérdida exponencial, corresponde a la reinterpretación estadística que realizan Friedman, Hastie y Tibshirani en el año 2000 (Friedman et al., 2000)<sup id="fnref2:friedman2000special"><a class="footnote-ref" href="#fn:friedman2000special">5</a></sup>. La formulación original de Freund y Schapire (Freund &amp; Schapire, 1997)<sup id="fnref3:freund1997decision"><a class="footnote-ref" href="#fn:freund1997decision">4</a></sup> partía de un marco de teoría de juegos y aprendizaje PAC (<em>Probably Approximately Correct</em>), llegando al mismo algoritmo desde una perspectiva diferente.</p>
</blockquote>
<h3 id="actualizacion-de-los-pesos">Actualización de los pesos<a class="headerlink" href="#actualizacion-de-los-pesos" title="Permanent link">¶</a></h3>
<p>Como hemos comentado, al final de cada iteración deberán ajustarse los pesos de cada ejemplo de entrenamiento, de forma que se le dé mayor peso a los ejemplos más difíciles (los peor clasificados hasta el momento), para que el siguiente clasificador se centre en mejorar su clasificación. </p>
<p>Siguiendo el proceso del algoritmo anterior, podemos considerar que hasta la iteración <span class="arithmatex">\(t-1\)</span> tendremos un <strong>clasificador fuerte</strong> <span class="arithmatex">\(F_{t-1}\)</span>, que se obtiene como:</p>
<div class="arithmatex">\[
F_{t-1}(\mathbf{x}) = \alpha_1 h_1(\mathbf{x}) + \alpha_2 h_2(\mathbf{x}) + \ldots + \alpha_{t-1} h_{t-1}(\mathbf{x})
\]</div>
<p>En la iteración <span class="arithmatex">\(t\)</span> buscaremos mejorarlo añadiendo un <strong>nuevo clasificador débil</strong> <span class="arithmatex">\(h_t\)</span>:</p>
<div class="arithmatex">\[
F_{t}(\mathbf{x}) = F_{t-1}(\mathbf{x}) + \alpha_t h_t(\mathbf{x}) 
\]</div>
<p>Buscamos que el nuevo clasificador débil minimice la pérdida <span class="arithmatex">\(L_t(y, F_t)\)</span>:</p>
<div class="arithmatex">\[
\begin{align*}
L_t(y, F_t) &amp;= \sum_{i=1}^N e^{-y_i F_t(\mathbf{x}_i)} = \\
&amp;=  \sum_{i=1}^N e^{-y_i (F_{t-1}(\mathbf{x}_i) + \alpha_t h_t(\mathbf{x}_i))} = \\
&amp;= \sum_{i=1}^N e^{-y_i F_{t-1}(\mathbf{x}_i)} e^{ - \alpha_t y_i h_t(\mathbf{x}_i)}
\end{align*}
\]</div>
<p>El primer factor <span class="arithmatex">\(e^{-y_i F_{t-1}(\mathbf{x}_i)}\)</span> no depende de lo que se está optimizando en este paso (<span class="arithmatex">\(\alpha_t\)</span> y <span class="arithmatex">\(h_t\)</span>), sino que actúa como una constante multiplicativa para cada ejemplo de entrada <span class="arithmatex">\(i\)</span>. De esta forma, consideramos esa constante como un peso <span class="arithmatex">\(w_i^{(t)}\)</span> que se define como:</p>
<div class="arithmatex">\[
w_i^{(t)} = e^{-y_i F_{t-1}(\mathbf{x}_i)}
\]</div>
<p>Este peso será mayor cuanto peor esté clasificado el ejemplo <span class="arithmatex">\(i\)</span> en el <em>ensemble</em> <span class="arithmatex">\(t-1\)</span>.</p>
<p>Reemplazándolo en la función de pérdida anterior tendríamos:</p>
<div class="arithmatex">\[
\begin{align*}
L_t(y, F_t) &amp;=  \sum_{i=1}^N w_i^{(t)} e^{ - \alpha_t y_i h_t(\mathbf{x}_i)}
\end{align*}
\]</div>
<p>Es decir, en la función de pérdida se le dará mayor peso a los ejemplos peor clasificados por el <em>ensemble</em> anterior <span class="arithmatex">\(t-1\)</span>.</p>
<p>Vamos a ver ahora la forma de actualizar los pesos. El peso para la siguiente iteración <span class="arithmatex">\(t+1\)</span> sería:</p>
<div class="arithmatex">\[
w_i^{(t+1)} = e^{-y_i F_{t}(\mathbf{x}_i)} =  e^{-y_i F_{t-1}(\mathbf{x}_i)} e^{ -  \alpha_t y_i h_t(\mathbf{x}_i)} = w_i^{(t)} e^{ - \alpha_t y_i h_t(\mathbf{x}_i)}
\]</div>
<p>Por lo tanto, tenemos la forma en la que se actualizarán los pesos tras cada iteración:</p>
<div class="arithmatex">\[ \quad w_i^{(t+1)} = w_i^{(t)} e^{-\alpha_t y_i h_t(\mathbf{x}_i)}  \quad \forall i 
\]</div>
<p>A partir de esta forma de actualizar los pesos, podemos observar que los ejemplos mal clasificados tendrán signo positivo en la exponencial, por lo que aumentará su peso, mientras que los bien clasificados tendrán signo negativo y en ese caso disminuirá su peso.</p>
<p>Además, deberemos normalizar los pesos para posteriormente poder calcular correctamente el error del clasificador a partir de ellos:</p>
<div class="arithmatex">\[
w_i^{(t+1)} = \frac{w_i^{(t+1)}}{\sum_{j=1}^N w_j^{(t+1)}}  \quad \forall i 
\]</div>
<blockquote>
<p><strong>Relación con la derivada</strong>: Si tratamos <span class="arithmatex">\(F(\mathbf{x}_i)\)</span> como una variable independiente para cada ejemplo de entrada <span class="arithmatex">\(\mathbf{x}_i\)</span>, y evaluamos cuánto afecta a la pérdida total calculando la derivada parcial, tenemos:</p>
<div class="arithmatex">\[ \frac{\partial L_t(y, F_{t})}{\partial F_{t}(\mathbf{x}_i)} = -y_i e^{-y_i F_{t}} \]</div>
<p>Si atendemos al gradiente negativo, podemos identificar dos partes:</p>
<ul>
<li><span class="arithmatex">\(y_i\)</span> nos indica la dirección, es decir, hacia dónde hay que mover <span class="arithmatex">\(F(\mathbf{x}_i)\)</span> para reducir la pérdida.</li>
<li><span class="arithmatex">\(e^{-y_i F_{t}}\)</span> nos indicará la magnitud, lo cual nos da una medida de cuánto importa el ejemplo <span class="arithmatex">\(\mathbf{x}_i\)</span> en este momento.
Por este motivo, definiremos este segundo término como el peso que le daremos a cada ejemplo de entrada. </li>
</ul>
</blockquote>
<h3 id="entrenar-un-clasificador-debil">Entrenar un clasificador débil<a class="headerlink" href="#entrenar-un-clasificador-debil" title="Permanent link">¶</a></h3>
<p>Buscamos minimizar la función de pérdida exponencial <span class="arithmatex">\(L(y, F_t)\)</span>, que a partir de la definición de los pesos expuesta en el apartado anterior, podemos escribir como:</p>
<div class="arithmatex">\[
L(y, F_t)  = \sum_{i=1}^N w_i^{(t)} e^{- \alpha_t y_i h_t(\mathbf{x}_i)}
\]</div>
<p>Si en la función separamos los ejemplos que se clasifican correcta e incorrectamente, tendríamos:</p>
<div class="arithmatex">\[
L(y, F_t) = \sum_{y_i = h_t(\mathbf{x}_i)} w_i^{(t)} e^{-\alpha_t } + \sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)} e^{\alpha_t }
\]</div>
<p>De forma equivalente, podría expresarse como:</p>
<div class="arithmatex">\[
L(y, F_t) = \sum_{i=1}^N w_i^{(t)} e^{-\alpha_t } + \sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)} (e^{\alpha_t } - e^{-\alpha_t })
\]</div>
<p>En la ecuación anterior, vemos que sólo el segundo término depende de <span class="arithmatex">\(h_t\)</span>. Por lo tanto, el clasificador que minimizará el error será aquel que minimice <span class="arithmatex">\(\sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)}\)</span>, es decir, la suma de los pesos de los ejemplos de entrada mal clasificados. Tendremos que entrenar los modelos base dando a cada ejemplo de entrada <span class="arithmatex">\((\mathbf{x}_i, y_i)\)</span> su correspondiente peso <span class="arithmatex">\(w_i^{(t)}\)</span>.</p>
<p>A nivel práctico, en sklearn, esto lo podremos hacer mediante el parámetro <code>sample_weight</code> de la función <code>fit</code>. Cada tipo de modelo tratará estos pesos de forma distinta. Por ejemplo, en el caso de Árboles de Decisión se tendrán en cuenta los pesos en el cálculo de la impureza de cada nodo, mientras que otros modelos como Regresión Logística o SVM incorporarán los pesos en su propia función de pérdida, haciendo que cada ejemplo contribuya a la pérdida con un factor proporcional a <span class="arithmatex">\(w_i^{(t)}\)</span>. Esto tiene la implicación de que solo podremos usar como modelos base en AdaBoost aquellos estimadores que soporten ese parámetro. </p>
<h3 id="calcular-el-peso-del-clasificador">Calcular el peso del clasificador<a class="headerlink" href="#calcular-el-peso-del-clasificador" title="Permanent link">¶</a></h3>
<p>Deberemos buscar el valor del peso de cada clasificador que <strong>minimice el error del <em>ensemble</em></strong>. Para hacer esto, en primer lugar derivaremos la función de pérdida respecto al peso <span class="arithmatex">\(\alpha_t\)</span> de cada clasificador:</p>
<div class="arithmatex">\[
\begin{align*}
\frac{\partial L(y, F_t)}{\partial \alpha_t} &amp;= \frac{\partial \left( \sum_{y_i = h_t(\mathbf{x}_i)} w_i^{(t)} e^{-\alpha_t } + \sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)} e^{\alpha_t } \right)}{\partial \alpha_t} = 
\\
&amp;= -\sum_{y_i = h_t(\mathbf{x}_i)} w_i^{(t)} e^{-\alpha_t } + \sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)} e^{\alpha_t }
\end{align*}
\]</div>
<p>Teniendo en cuenta que la función de error es una función convexa, la igualaremos a <span class="arithmatex">\(0\)</span> para buscar el punto en la que es mínima:</p>
<div class="arithmatex">\[
-\sum_{y_i = h_t(\mathbf{x}_i)} w_i^{(t)} e^{-\alpha_t } + \sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)} e^{\alpha_t } = 0
\]</div>
<div class="arithmatex">\[
\Downarrow
\]</div>
<div class="arithmatex">\[
\sum_{y_i = h_t(\mathbf{x}_i)} w_i^{(t)} e^{-\alpha_t } = \sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)} e^{\alpha_t }
\]</div>
<div class="arithmatex">\[
\Downarrow
\]</div>
<div class="arithmatex">\[
\frac{\sum_{y_i = h_t(\mathbf{x}_i)} w_i^{(t)}}{\sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)}} = \frac{e^{\alpha_t }}{e^{-\alpha_t }} = e^{2\alpha_t}
\]</div>
<p>Por lo tanto, tenemos:</p>
<div class="arithmatex">\[
\alpha_t = \frac{1}{2} \ln \frac{\sum_{y_i = h_t(\mathbf{x}_i)} w_i^{(t)}}{\sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)}}
\]</div>
<p>Considerando que los pesos están normalizados, podemos definir el error <span class="arithmatex">\(\epsilon_t\)</span> del clasificador débil <span class="arithmatex">\(h_t\)</span>, de la siguiente forma:</p>
<div class="arithmatex">\[
\epsilon_t = \sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)}
\]</div>
<p>Observamos que calculamos el error de <span class="arithmatex">\(h_t\)</span> como la suma de los pesos de los ejemplos mal clasificados por dicho clasificador débil. De esta forma, el clasificador tendrá error bajo cuando el peso total de los ejemplos mal clasificados sea bajo, y los ejemplos de mayor peso hayan sido correctamente clasificados. </p>
<p>Teniendo esta definición en cuenta, y considerando que los pesos están normalizados y que por lo tanto <span class="arithmatex">\(\sum_{i=1}^N w_i^{(t)} = 1\)</span>, tenemos:</p>
<div class="arithmatex">\[
\begin{align*}
\alpha_t &amp;= \frac{1}{2} \ln \frac{\sum_{y_i = h_t(\mathbf{x}_i)} w_i^{(t)}}{\sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)}} = \\
&amp;= \frac{1}{2} \ln \frac{\sum_{i=1}^N w_i^{(t)} - \sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)}}{\sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)}} = \\
&amp;= \frac{1}{2} \ln \frac{1-\epsilon_t}{\epsilon_t}
\end{align*}
\]</div>
<p>Con esto podemos observar que <span class="arithmatex">\(\alpha_t\)</span> será mayor cuanto menor error <span class="arithmatex">\(\epsilon_t\)</span> tenga el clasificador. Lo peor que pueda ocurrir es que <span class="arithmatex">\(\epsilon_t = 0.5\)</span>, ya que en ese caso el clasificador equivale a lanzar una moneda al aire, y en tal caso tendremos un peso <span class="arithmatex">\(\alpha_t = 0\)</span>. Podemos observar también que si <span class="arithmatex">\(\epsilon_t &gt; 0.5\)</span> (peor que el azar), el peso pasará a ser negativo, es decir, se invierte el clasificador para que así pase a ser algo mejor que el azar.  </p>
<h3 id="algoritmo-detallado">Algoritmo detallado<a class="headerlink" href="#algoritmo-detallado" title="Permanent link">¶</a></h3>
<p>Con todo lo anterior, podemos escribir de forma completa el algoritmo AdaBoost detallando en cada paso la forma en la que se calculan los errores y los pesos:</p>
<div class="arithmatex">\[
\begin{align*}
&amp; \text{Entrada: } \text{Conjunto de entrenamiento } \mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^N \text{ con } y_i \in \{-1, +1\} \\
&amp; w_i^{(1)} \leftarrow \frac{1}{N} \quad \forall i \in 1, 2, \ldots, N \quad \text{(Inicializa todos los ejemplos con peso uniforme)} \\
&amp; \text{Para  } t = 1, \ldots, T \\
&amp; \quad h_t \leftarrow \text{Entrenar un clasificador débil que minimice } \sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)} \\
&amp; \quad \epsilon_t \leftarrow \sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)} \quad \text{(Calcular el error del clasificador débil)} \\
&amp; \quad \alpha_t \leftarrow \frac{1}{2} \ln \left( \frac{1-\epsilon_t}{\epsilon_t} \right) \quad \text{(Calcular el peso del clasificador)}  \\
&amp; \quad w_i^{(t+1)} \leftarrow w_i^{(t)} e^{-\alpha_t y_i h_t(\mathbf{x}_i)}  \quad \forall i \quad \text{(Actualiza los pesos de los ejemplos para el siguiente clasificador)} \\
&amp; \quad w_i^{(t+1)} \leftarrow \frac{w_i^{(t+1)}}{\sum_{j=1}^N w_j^{(t+1)}}  \quad \forall i \quad \text{(Normaliza los nuevos pesos)} \\
&amp; \text{Devuelve: } H(\mathbf{x}) = \text{signo} \left( F(\mathbf{x}) \right) = \text{signo} \left( \sum_{t=1}^T \alpha_t h_t(\mathbf{x}) \right)
\end{align*}
\]</div>
<h2 id="propiedades-de-adaboost">Propiedades de AdaBoost<a class="headerlink" href="#propiedades-de-adaboost" title="Permanent link">¶</a></h2>
<h3 id="adaptatividad">Adaptatividad<a class="headerlink" href="#adaptatividad" title="Permanent link">¶</a></h3>
<p>Una propiedad importante de AdaBoost es su adaptatividad, lo cual le da el nombre (<strong>Ada</strong>ptative <strong>Boost</strong>ing). El término "adaptativo" tiene además dos significados:</p>
<ul>
<li>
<p><strong>Adaptación a los datos de entrada</strong>: Los pesos <span class="arithmatex">\(w_i\)</span> se ajustan en función de los ejemplos que se clasifican mal. El algoritmo es capaz de identificar estos ejemplos a partir de los errores observados, y se concentra en ellos.</p>
</li>
<li>
<p><strong>Adaptación a la calidad de los clasificadores base</strong>: El peso <span class="arithmatex">\(\alpha_t\)</span> que recibe cada clasificador no se fija de antemano, sino que el algoritmo lo calcula de forma automática a partir del error <span class="arithmatex">\(\epsilon_t\)</span>. A diferencia de propuestas previas de métodos de <em>Boosting</em>, no es necesario conocer de antemano la calidad de los clasificadores base ni su error, sino que se adaptará automáticamente a partir del error observado.</p>
</li>
</ul>
<h3 id="cota-del-error-de-entrenamiento">Cota del error de entrenamiento<a class="headerlink" href="#cota-del-error-de-entrenamiento" title="Permanent link">¶</a></h3>
<p>AdaBoost tiene una garantía teórica sobre el error de entrenamiento (Schapire &amp; Freund, 2012)<sup id="fnref:schapire2012boosting"><a class="footnote-ref" href="#fn:schapire2012boosting">6</a></sup> tras <span class="arithmatex">\(T\)</span> iteraciones:</p>
<div class="arithmatex">\[\frac{1}{N} \sum_{i=1}^N 1(H(\mathbf{x}_i) \neq y_i) \leq \prod_{t=1}^{T} 2 \sqrt{\epsilon_t(1-\epsilon_t)} \leq \exp\left(-2\sum_{t=1}^{T}\gamma_t^2\right)\]</div>
<p>Donde <span class="arithmatex">\(\gamma_t = \frac{1}{2} - \epsilon_t\)</span> es el margen o ventaja del clasificador débil <span class="arithmatex">\(h_t\)</span> sobre el azar. Podemos ver que si cada clasificador supera al azar, aunque sea por poco (<span class="arithmatex">\(\gamma_t &gt; 0\)</span>), el error de entrenamiento decrece.</p>
<p>Podemos simplificar la cota anterior, considerando que todos los clasificadores tienen al menos una ventaja mínima uniforme <span class="arithmatex">\(\gamma_t \geq \gamma \gt 0\)</span>, de la siguiente forma:</p>
<div class="arithmatex">\[\text{Training Error} \leq \exp\left(-2 T \gamma^2\right)\]</div>
<p>Aquí podemos ver más claramente la implicación de esta cota, y es que el error de entrenamiento <strong>decrece exponencialmente con el número de iteraciones <span class="arithmatex">\(T\)</span></strong>. Basta que cada clasificador sea ligeramente mejor que el azar para que el error de entrenamiento se reduzca a cero.</p>
<h2 id="variantes-de-adaboost">Variantes de AdaBoost<a class="headerlink" href="#variantes-de-adaboost" title="Permanent link">¶</a></h2>
<p>El algoritmo AdaBoost original (Freund &amp; Schapire, 1997)<sup id="fnref2:freund1997decision"><a class="footnote-ref" href="#fn:freund1997decision">4</a></sup> está diseñado para clasificación binaria, pero desde su publicación se han propuesto numerosas variantes que amplían su aplicabilidad a clasificación multiclase, regresión, y escenarios con distintos requisitos de robustez. </p>
<p>Encontramos diferentes variantes para clasificación binaria, como Real AdaBoost (Schapire &amp; Singer, 1999)<sup id="fnref:schapire1999improved"><a class="footnote-ref" href="#fn:schapire1999improved">7</a></sup>, Gentle AdaBoost y LogitAdaBoost (Friedman et al., 2000)<sup id="fnref:friedman2000special"><a class="footnote-ref" href="#fn:friedman2000special">5</a></sup>. También tenemos extensiones para clasificación multiclase, como AdaBoost.M1 / AdaBoost.M2 (Freund &amp; Schapire, 1996)<sup id="fnref:freund1996experiments"><a class="footnote-ref" href="#fn:freund1996experiments">8</a></sup> y SAMME / SAMME.R (Zhu et al., 2009)<sup id="fnref:zhu2009multi"><a class="footnote-ref" href="#fn:zhu2009multi">9</a></sup>. Por otro lado, también tenemos AdaBoost.R2 (Drucker, 1997)<sup id="fnref:drucker1997improving"><a class="footnote-ref" href="#fn:drucker1997improving">10</a></sup>, una adaptación al caso continuo enfocada a problemas de regresión.</p>
<p>Vamos a centrarnos en las más relevantes: SAMME para problemas de clasificación multiclase y AdaBoost.R2 para regresión. </p>
<h3 id="clasificacion-multiclase-con-samme">Clasificación multiclase con SAMME<a class="headerlink" href="#clasificacion-multiclase-con-samme" title="Permanent link">¶</a></h3>
<p>SAMME (<em>Stagewise Additive Modeling using a Multi-class Exponential loss</em>) (Zhu et al., 2009)<sup id="fnref2:zhu2009multi"><a class="footnote-ref" href="#fn:zhu2009multi">9</a></sup> es la generalización más comúnmente utilizada de AdaBoost al caso multiclase, y cuenta con una sólida base teórica. </p>
<p>El problema fundamental al pasar a clasificación multiclase es que la condición de debilidad <span class="arithmatex">\(\epsilon_t &lt; 0.5\)</span> es demasiado estricta cuando el número de clases aumenta. El azar uniforme entre <span class="arithmatex">\(K\)</span> clases corresponde a un error de <span class="arithmatex">\(1 - \frac{1}{K}\)</span>, que para <span class="arithmatex">\(K \geq 3\)</span> supera <span class="arithmatex">\(0.5\)</span>. Exigir <span class="arithmatex">\(\epsilon_t &lt; 0.5\)</span> equivale entonces a pedir que el clasificador base supere al azar binario en un problema que no lo es, lo que resulta cada vez más difícil a medida que <span class="arithmatex">\(K\)</span> crece.</p>
<p>Si consideramos el caso del azar para cada <span class="arithmatex">\(K\)</span> clases, tendríamos <span class="arithmatex">\(\epsilon_t = 1 - \frac{1}{K}\)</span>. En tal caso, si no introducimos ninguna corrección en el cálculo de los pesos quedaría lo siguiente:</p>
<div class="arithmatex">\[
\begin{align*}
\alpha_t &amp;= \ln\frac{1 - \epsilon_t}{\epsilon_t} = \ln\frac{1 - 1 + \frac{1}{K}}{1-\frac{1}{K}} = \ln\frac{\frac{1}{K}}{1-\frac{1}{K}} =\\
&amp; = \ln\frac{1}{K-1} = -\ln (K-1)
\end{align*}
\]</div>
<p>Para un número de clases <span class="arithmatex">\(K &gt; 2\)</span> nos estará dando un peso negativo del clasificador, cuando realmente debería darnos un peso <span class="arithmatex">\(0\)</span>, ya que esta situación corresponde al azar. Por este motivo, la principal modificación clave que introduce SAMME está en modificar la forma de calcular el peso de cada clasificador como se muestra a continuación:</p>
<div class="arithmatex">\[\alpha_t = \ln\frac{1 - \epsilon_t}{\epsilon_t} + \ln(K - 1)\]</div>
<p>El término adicional <span class="arithmatex">\(\ln(K-1)\)</span> tiene dos consecuencias importantes:</p>
<ul>
<li>
<p>En primer lugar, la condición de debilidad pasa a ser <span class="arithmatex">\(\epsilon_t &lt; 1 - \frac{1}{K}\)</span>, que corresponde a superar al azar uniforme entre <span class="arithmatex">\(K\)</span> clases, lo cual es la condición teóricamente correcta. Cuando un clasificador funcione igual que el azar, su peso será <span class="arithmatex">\(0\)</span>.</p>
</li>
<li>
<p>En segundo lugar, para <span class="arithmatex">\(K = 2\)</span> se tiene <span class="arithmatex">\(\ln(K-1) = \ln 1 = 0\)</span> y el algoritmo producirá las mismas predicciones que AdaBoost binario, confirmando que es una generalización consistente.</p>
</li>
</ul>
<p>El algoritmo completo de entrenamiento es el siguiente:</p>
<div class="arithmatex">\[
\begin{align*}
&amp; \text{Entrada: } \text{Conjunto de entrenamiento } \mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^N \text{ con } y_i \in \{1, \ldots, K\} \\
&amp; w_i^{(1)} \leftarrow \frac{1}{N} \quad \forall i \in 1, 2, \ldots, N \quad \text{(Inicializa todos los ejemplos con peso uniforme)} \\
&amp; \text{Para  } t = 1, \ldots, T \\
&amp; \quad h_t \leftarrow \text{Entrenar un clasificador débil que minimice } \sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)} \\
&amp; \quad \epsilon_t \leftarrow \sum_{y_i \neq h_t(\mathbf{x}_i)} w_i^{(t)} \quad \text{(Calcular el error del clasificador débil)} \\
&amp; \quad \text{Si } \epsilon_t \geq 1 - \frac{1}{K} \text{: detener} \\
&amp; \quad \alpha_t \leftarrow  \ln \left( \frac{1-\epsilon_t}{\epsilon_t} \right) + \ln(K-1) \quad \text{(Calcular el peso del clasificador)}  \\
&amp; \quad w_i^{(t+1)} \leftarrow w_i^{(t)} e^{\alpha_t \cdot \mathbb{1}(h_t(\mathbf{x}_i) \neq y_i)}  \quad \forall i \quad \text{(Actualiza los pesos de los ejemplos para el siguiente clasificador)} \\
&amp; \quad w_i^{(t+1)} \leftarrow \frac{w_i^{(t+1)}}{\sum_{j=1}^N w_j^{(t+1)}}  \quad \forall i \quad \text{(Normaliza los nuevos pesos)} \\
&amp; \text{Devuelve: } H(\mathbf{x}) = \arg \max_k  \sum_{t: h_t(\mathbf{x})=k} \alpha_t 
\end{align*}
\]</div>
<p>La predicción final asigna a cada clase la suma de pesos de los clasificadores que la predicen, eligiendo la clase con mayor suma acumulada.</p>
<h3 id="adaboostr2-para-regresion">AdaBoost.R2 para regresión<a class="headerlink" href="#adaboostr2-para-regresion" title="Permanent link">¶</a></h3>
<p>AdaBoost.R2 (Drucker, 1997)<sup id="fnref2:drucker1997improving"><a class="footnote-ref" href="#fn:drucker1997improving">10</a></sup> adapta AdaBoost al problema de regresión. La dificultad principal es que en regresión no existe un concepto de "azar" tan claro como en clasificación, y el error no puede definirse como una proporción de ejemplos mal clasificados.</p>
<p>Lo que plantea esta variante es normalizar el error de cada ejemplo al rango <span class="arithmatex">\([0,1]\)</span>, para así poder recuperar la condición de debilidad <span class="arithmatex">\(\epsilon_t &lt; 0.5\)</span>. Para cada ejemplo <span class="arithmatex">\(i\)</span> y cada iteración <span class="arithmatex">\(t\)</span>, se define la <strong>pérdida normalizada</strong> de la siguiente forma:</p>
<div class="arithmatex">\[L_i^{(t)} = \frac{|y_i - h_t(\mathbf{x}_i)|}{\max_j |y_j - h_t(\mathbf{x}_j)|}\]</div>
<p>Esta pérdida normalizada toma valores en <span class="arithmatex">\([0,1]\)</span> y mide el error relativo al peor error cometido por el regresor base en esa iteración. El ejemplo con peor error tendrá <span class="arithmatex">\(L_i^{(t)}=1\)</span>, y el que mejor se ajuste tendrá un valor cercano a <span class="arithmatex">\(0\)</span>. Hay variantes que en lugar de utilizar error lineal utilizan error cuadrático o exponencial.  </p>
<p>A partir de la pérdida normalizada calculamos el <strong>error ponderado del regresor base</strong>:</p>
<div class="arithmatex">\[\epsilon_t = \sum_{i=1}^{N} w_i^{(t)} L_i^{(t)}\]</div>
<p>Dado que la condición de debilidad es <span class="arithmatex">\(\epsilon_t &lt; 0.5\)</span>, si obtenemos <span class="arithmatex">\(\epsilon_t \geq 0.5\)</span> el algoritmo se detendrá. Podemos interpretar este error ponderado como una esperanza. Es decir, <span class="arithmatex">\(\epsilon_t\)</span> sería el valor esperado del error normalizado bajo la distribución de pesos actual. </p>
<p>Como pesos para los estimadores <span class="arithmatex">\(h_t\)</span>, en regresión en lugar de utilizar <span class="arithmatex">\(\alpha_t\)</span> utilizaremos <span class="arithmatex">\(\beta_t\)</span>, que se calcula de la siguiente forma:</p>
<div class="arithmatex">\[
\beta_t = \frac{\epsilon_t}{1 - \epsilon_t}
\]</div>
<p>El valor de este peso estará dentro del rango <span class="arithmatex">\(\beta_t \in (0,1)\)</span> cuando se cumpla la condición <span class="arithmatex">\(\epsilon_t &lt; 0.5\)</span>. Tendríamos <span class="arithmatex">\(\beta_t = 1\)</span> en caso de tener un regresor muy malo, justo en el límite <span class="arithmatex">\(\epsilon_t = 0.5\)</span>, y el valor será menor conforme mejor sea el regresor, aproximándose a <span class="arithmatex">\(0\)</span> en los mejores casos.</p>
<p>La actualización de los pesos se hará de la siguiente forma:</p>
<div class="arithmatex">\[
w_i^{(t+1)} = w_i^{(t)} \beta_t^{1-L_i^{(t)}}
\]</div>
<p>Interpretando el exponente de la actualización anterior tenemos:</p>
<ul>
<li>
<p>Si el error del ejemplo <span class="arithmatex">\(i\)</span> es pequeño (<span class="arithmatex">\(L_i^{(t)}\)</span> es cercano a <span class="arithmatex">\(0\)</span>), entonces el exponente será cercano a <span class="arithmatex">\(1\)</span> y el peso se multiplica por <span class="arithmatex">\(\beta_t &lt; 1\)</span>, lo cual hará que se reduzca.</p>
</li>
<li>
<p>Si por el contrario el error del ejemplo <span class="arithmatex">\(i\)</span> es máximo (<span class="arithmatex">\(L_i^{(t)}\)</span> es <span class="arithmatex">\(1\)</span>), entonces el exponente será  <span class="arithmatex">\(0\)</span> y el peso se multiplica por <span class="arithmatex">\(\beta_t^0 = 1\)</span>, manteniendo su valor.</p>
</li>
</ul>
<p>Al igual que en el caso de clasificación, esto hará que el peso de los ejemplos difíciles crezca, mientras que los fáciles perderán peso.</p>
<p>AdaBoost.R2 difiere considerablemente respecto a AdaBoost en la forma de obtener la predicción final. En lugar de una suma ponderada de predicciones, se obtendrá mediante una mediana ponderada. La elección de la mediana en lugar de la media se debe a que la mediana será más robusta frente a predicciones extremas de regresores de baja calidad.</p>
<p>A continuación se muestra el algoritmo completo:</p>
<div class="arithmatex">\[
\begin{align*}
&amp; \text{Entrada: } \text{Conjunto de entrenamiento } \mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^N \\
&amp; w_i^{(1)} \leftarrow \frac{1}{N} \quad \forall i \in 1, 2, \ldots, N \quad \text{(Inicializa todos los ejemplos con peso uniforme)} \\
&amp; \text{Para  } t = 1, \ldots, T \\
&amp; \quad h_t \leftarrow \text{Entrenar regresor base con pesos } w_i^{(t)} \\
&amp; \quad L_i^{(t)} \leftarrow \frac{|y_i - h_t(\mathbf{x}_i)|}{\max_j |y_j - h_t(\mathbf{x}_j)|} \quad \forall i \quad \text{(Pérdida normalizada)}  \\
&amp; \quad \epsilon_t \leftarrow \sum_{i=1}^{N} w_i^{(t)}  L_i^{(t)} \quad \text{(Error ponderado del regresor base)}  \\
&amp; \quad \beta_t \leftarrow \frac{\epsilon_t}{1 - \epsilon_t} \quad \text{(Calcula el peso del regresor)}  \\
&amp; \quad w_i^{(t+1)} \leftarrow w_i^{(t)}  \beta_t^{1 - L_i^{(t)}} \quad \forall i \quad \text{(Actualización de pesos de los ejemplos)}  \\
&amp; \quad w_i^{(t+1)} \leftarrow \frac{w_i^{(t+1)}}{\sum_{j=1}^N w_j^{(t+1)}}  \quad \forall i \quad \text{(Normaliza los nuevos pesos)} \\
&amp; \text{Devuelve: } H(\mathbf{x}) = \text{mediana ponderada de } \{h_t(\mathbf{x})\}_{t=1}^T \text{ con pesos } \ln\frac{1}{\beta_t} 
\end{align*}
\]</div>
<p>Observamos que la actualización de pesos actúa de forma inversa a la clasificación: los ejemplos con <strong>error pequeño</strong> (<span class="arithmatex">\(L_i^{(t)} \approx 0\)</span>) reducen su peso, ya que <span class="arithmatex">\(\beta_t^{1-L_i^{(t)}} \approx \beta_t &lt; 1\)</span>, mientras que los ejemplos difíciles conservan o aumentan su importancia relativa.</p>
<p>La predicción final es la <strong>mediana ponderada</strong> de los regresores base, donde el peso de cada regresor es <span class="arithmatex">\(\ln(1/\beta_t)\)</span>: los regresores con menor error ponderado <span class="arithmatex">\(\epsilon_t\)</span> tienen mayor <span class="arithmatex">\(\ln(1/\beta_t)\)</span> y por tanto contribuyen más.</p>
<h2 id="implementacion">Implementación<a class="headerlink" href="#implementacion" title="Permanent link">¶</a></h2>
<p>En sklearn contamos con las implementaciones <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html">AdaBoostClassifier</a> y <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html">AdaBoostRegressor</a> para problemas de clasificación y regresión, respectivamente.</p>
<p>En este caso, <code>AdaBoostClassifier</code> implementa el algoritmo SAMME, mientras que <code>AdaBoostRegressor</code> implementa AdaBoost.R2. </p>
<p>A continuación podemos ver un ejemplo de código que utiliza AdaBoost para clasificación con <em>decision stumps</em>, lo cual es la opción por defecto.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">ada</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># Decision stump</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span>         <span class="c1"># Número de clasificadores débiles</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="p">)</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="n">ada</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="c1"># Inspeccionar clasificadores y pesos</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="nb">print</span><span class="p">(</span><span class="s2">"Pesos de clasificadores:"</span><span class="p">,</span> <span class="n">ada</span><span class="o">.</span><span class="n">estimator_weights_</span><span class="p">)</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="nb">print</span><span class="p">(</span><span class="s2">"Errores de clasificadores:"</span><span class="p">,</span> <span class="n">ada</span><span class="o">.</span><span class="n">estimator_errors_</span><span class="p">)</span>
</code></pre></div>
<p>De igual forma, a continuación incluimos un ejemplo de regresión:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="n">reg</span> <span class="o">=</span> <span class="n">AdaBoostRegressor</span><span class="p">(</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>    <span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>    <span class="n">loss</span><span class="o">=</span><span class="s1">'linear'</span>   
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="p">)</span>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<p>En este caso contamos con el parámetro <code>loss</code> que permite elegir cómo se calcula la pérdida normalizada <span class="arithmatex">\(L_i^{(t)}\)</span>. Con <code>'linear'</code> se usa el error absoluto normalizado (el descrito en el algoritmo anterior), con <code>'square'</code> el error cuadrático normalizado, y con <code>'exponential'</code> una pérdida exponencial normalizada. La opción <code>'linear'</code> es la correspondiente al algoritmo AdaBoost.R2 original y suele ser la más robusta.</p>
<h2 id="consideraciones-finales">Consideraciones finales<a class="headerlink" href="#consideraciones-finales" title="Permanent link">¶</a></h2>
<p>AdaBoost tiene varias ventajas. Es fácil de entender e implementar, puede funcionar con cualquier clasificador débil y tiene pocos hiperparámetros. No necesitamos conocer los errores <span class="arithmatex">\(\epsilon_t\)</span>, el algoritmo se adapta automáticamente. Puede alcanzar buenos resultados con clasificadores muy simples.</p>
<p>Sin embargo, también encontramos una serie de desventajas. No es paralelizable como otros tipos de <em>ensembles</em> y puede ser costoso si contamos con clasificadores débiles lentos. Debemos tener en cuenta también que no funciona con clasificadores débiles peores que el azar.</p>
<p>La principal desventaja que deberemos tener en cuenta es que es muy <strong>sensible al ruido y a los <em>outliers</em></strong>. Hemos visto que al utilizar la función de pérdida exponencial, se da un peso desmesurado a ejemplos muy mal clasificados, dominando así la optimización. Esto hará que AdaBoost acabará dedicando casi toda su capacidad a intentar clasificar correctamente un ejemplo imposible, degradando el rendimiento en el resto. </p>
<p>Pero si AdaBoost equivale a minimizar la pérdida exponencial, ¿qué ocurriría si <strong>cambiamos esa función de pérdida</strong>? Si utilizamos pérdida logística tendremos la variante LogitBoost que será más robusta frente al ruido al crecer linealmente para errores grandes. Si generalizamos para cualquier función de pérdida diferenciable obtendremos <strong>Gradient Boosting</strong>, que estudiaremos en la siguiente sesión.</p>
<p>En el caso de <strong>regresión</strong> encontramos que AdaBoost.R2 presenta dos debilidades estructurales:</p>
<ul>
<li>
<p>La primera es que la normalización por el máximo error hace el algoritmo muy sensible a <strong>outliers</strong>, al igual que ocurre en el caso de la clasificación. Un único ejemplo con un error enorme hace que el denominador sea muy grande y que todos los demás errores normalizados sean casi cero, lo que distorsiona completamente el cálculo de <span class="arithmatex">\(\epsilon_t\)</span> y de los pesos.</p>
</li>
<li>
<p>La segunda es que la elección de la función de pérdida no viene de un marco teórico coherente como en el caso de la clasificación. En clasificación, la actualización de pesos se deriva directamente de la pérdida exponencial. En AdaBoost.R2, la normalización y la actualización son heurísticas razonables pero no tienen una justificación como minimizadores de ninguna función de pérdida concreta.</p>
</li>
</ul>
<p><strong>Gradient Boosting</strong> resuelve ambos problemas: permite elegir explícitamente la función de pérdida en función de las necesidades del problema, y está teóricamente bien fundamentado. Por ello, en la práctica AdaBoost.R2 ha sido ampliamente superado por Gradient Boosting.</p>
<p>Tanto si tenemos un problema de regresión, como si en el caso de clasificación tenemos mucho ruido y <em>outliers</em> o buscamos máximo rendimiento, convendrá considerar como alternativa métodos de <em>Gradient Boosting</em>.  </p>
<div class="footnote">
<hr>
<ol>
<li id="fn:kearns1988cryptographic">
<p>Kearns, M., &amp; Valiant, L. G. (1988). <em>Learning Boolean formulae or finite automata is as hard as factoring</em> (Nos. TR-14-88). Harvard University Aiken Computation Laboratory.&nbsp;<a class="footnote-backref" href="#fnref:kearns1988cryptographic" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:kearns1989cryptographic">
<p>Kearns, M., &amp; Valiant, L. G. (1989). Cryptographic limitations on learning Boolean formulae and finite automata. <em>Proceedings of the 21st Annual ACM Symposium on Theory of Computing (STOC'89)</em>, 433--444. <a href="https://doi.org/10.1145/73007.73049">https://doi.org/10.1145/73007.73049</a>&nbsp;<a class="footnote-backref" href="#fnref:kearns1989cryptographic" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:schapire1990strength">
<p>Schapire, R. E. (1990). The strength of weak learnability. <em>Machine Learning</em>, <em>5</em>(2), 197--227.&nbsp;<a class="footnote-backref" href="#fnref:schapire1990strength" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
<li id="fn:freund1997decision">
<p>Freund, Y., &amp; Schapire, R. E. (1997). A decision-theoretic generalization of on-line learning and an application to boosting. <em>Journal of Computer and System Sciences</em>, <em>55</em>(1), 119--139.&nbsp;<a class="footnote-backref" href="#fnref:freund1997decision" title="Jump back to footnote 4 in the text">↩</a><a class="footnote-backref" href="#fnref2:freund1997decision" title="Jump back to footnote 4 in the text">↩</a><a class="footnote-backref" href="#fnref3:freund1997decision" title="Jump back to footnote 4 in the text">↩</a></p>
</li>
<li id="fn:friedman2000special">
<p>Friedman, J., Hastie, T., &amp; Tibshirani, R. (2000). Additive logistic regression: A statistical view of boosting (Special Invited Paper). <em>The Annals of Statistics</em>, <em>28</em>(2), 337--407. <a href="https://doi.org/10.1214/aos/1016218223">https://doi.org/10.1214/aos/1016218223</a>&nbsp;<a class="footnote-backref" href="#fnref:friedman2000special" title="Jump back to footnote 5 in the text">↩</a><a class="footnote-backref" href="#fnref2:friedman2000special" title="Jump back to footnote 5 in the text">↩</a></p>
</li>
<li id="fn:schapire2012boosting">
<p>Schapire, R. E., &amp; Freund, Y. (2012). <em>Boosting: Foundations and algorithms</em>. MIT Press.&nbsp;<a class="footnote-backref" href="#fnref:schapire2012boosting" title="Jump back to footnote 6 in the text">↩</a></p>
</li>
<li id="fn:schapire1999improved">
<p>Schapire, R. E., &amp; Singer, Y. (1999). Improved boosting algorithms using confidence-rated predictions. <em>Machine Learning</em>, <em>37</em>(3), 297--336. <a href="https://doi.org/10.1023/A:1007614523901">https://doi.org/10.1023/A:1007614523901</a>&nbsp;<a class="footnote-backref" href="#fnref:schapire1999improved" title="Jump back to footnote 7 in the text">↩</a></p>
</li>
<li id="fn:freund1996experiments">
<p>Freund, Y., &amp; Schapire, R. E. (1996). Experiments with a new boosting algorithm. In L. Saitta (Ed.), <em>Proceedings of the 13th international conference on machine learning (ICML'96)</em> (pp. 148--156). Morgan Kaufmann.&nbsp;<a class="footnote-backref" href="#fnref:freund1996experiments" title="Jump back to footnote 8 in the text">↩</a></p>
</li>
<li id="fn:zhu2009multi">
<p>Zhu, J., Rosset, S., Zou, H., &amp; Hastie, T. (2009). Multi-class AdaBoost. <em>Statistics and Its Interface</em>, <em>2</em>(3), 349--360. <a href="https://doi.org/10.4310/SII.2009.v2.n3.a8">https://doi.org/10.4310/SII.2009.v2.n3.a8</a>&nbsp;<a class="footnote-backref" href="#fnref:zhu2009multi" title="Jump back to footnote 9 in the text">↩</a><a class="footnote-backref" href="#fnref2:zhu2009multi" title="Jump back to footnote 9 in the text">↩</a></p>
</li>
<li id="fn:drucker1997improving">
<p>Drucker, H. (1997). Improving regressors using boosting techniques. <em>Proceedings of the 14th International Conference on Machine Learning (ICML'97)</em>, 107--115.&nbsp;<a class="footnote-backref" href="#fnref:drucker1997improving" title="Jump back to footnote 10 in the text">↩</a><a class="footnote-backref" href="#fnref2:drucker1997improving" title="Jump back to footnote 10 in the text">↩</a></p>
</li>
</ol>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg>
            Volver al principio
          </a>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.sections", "navigation.expand", "navigation.top", "navigation.indexes", "toc.follow", "toc.integrate", "search.suggest", "search.highlight", "content.code.copy", "content.code.annotate"], "search": "../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copiado al portapapeles", "clipboard.copy": "Copiar al portapapeles", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.term.missing": "Falta", "select.version": "Seleccionar versi\u00f3n"}}</script>
    
    
      <script src="../assets/javascripts/bundle.b78d2936.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>